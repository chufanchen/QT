defaults:
  - _self_

seed: 123

# Common settings
warmup_steps: 10000
num_eval_episodes: 10
max_iters: 500
num_steps_per_iter: 10000
early_stop: true
early_epoch: 100
batch_size: 32

discount: 0.99
use_discount: true
k_rewards: true
reward_tune: no
sar: false
scale: null
test_scale: null
rtg_no_q: false
infer_no_q: false

tau: 0.005
alpha: 0.01
eta: 1.0
eta2: 1.0
lambda: 1.0
lambda1: 1.0
max_q_backup: true
K: 5
grad_norm: 15.0

log_to_wandb: true
save_path: ./save/

# Model architecture
n_layer: 3
embed_dim: 128
n_head: 4
activation_function: relu
dropout: 0.1
learning_rate: 0.0001
lr_decay: true
lr_min: 0.0
weight_decay: 1e-4

dataset_postfix: null
create_pct_traj_and_exit: false
value_penalty: false

wandb_param:
  project: erqt
  tags: ["halfcheetah"]

# Environment settings
env: halfcheetah
dataset: medium-expert
use_aug: true
pct_traj: 0.1

# Model settings
model_type: qdt
stochastic_policy: true
policy_penalty: true

# Training settings
behavior_ckpt_file: ./save/10%_bc_stochastic-halfcheetah-medium-replay-123-250324-112957/epoch_15.pth

# Logging settings
exp_name: erqt-gaussian-no-lr-decay
project_name: erqt 